{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIjb-fLJs6KI",
        "outputId": "c0f40674-0cc7-48e6-88ef-aa4b2264e3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.70-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 654 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Installing collected packages: requests, lxml, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed lxml-4.8.0 requests-2.27.1 yfinance-0.1.70\n"
          ]
        }
      ],
      "source": [
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install psaw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMB3IeWfFW8D",
        "outputId": "cc729f94-cb3d-401c-e23b-6e452104f8fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting psaw\n",
            "  Downloading psaw-0.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from psaw) (2.27.1)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from psaw) (7.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->psaw) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->psaw) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->psaw) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->psaw) (2.0.12)\n",
            "Installing collected packages: psaw\n",
            "Successfully installed psaw-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "31DZAlWKRzQ_"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from dateutil.parser import parse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
        "import seaborn as sns\n",
        "sns.set_context(\"paper\", font_scale=1.3)\n",
        "sns.set_style('white')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from time import time\n",
        "import matplotlib.ticker as tkr\n",
        "from scipy import stats\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn import preprocessing\n",
        "from statsmodels.tsa.stattools import pacf\n",
        "%matplotlib inline\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import time\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "import datetime\n",
        "from math import log, sqrt, pi, exp\n",
        "from scipy.stats import norm\n",
        "from datetime import datetime, date, timedelta\n",
        "from pandas import DataFrame\n",
        "import pandas as pd\n",
        "from bs4.element import DEFAULT_OUTPUT_ENCODING\n",
        "\n",
        "\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbl-HvfLLLaq"
      },
      "source": [
        "**Option version (default must be on)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJF8eU9m7ZPY"
      },
      "source": [
        "**Turning it into a function to compare predictions (scroll down)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdfYPRFHGaOA",
        "outputId": "3c7d3e0f-7929-4f78-bd7c-31a606ca7189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the # of categories you would like to analyze (3 MAX)\n",
            "3\n",
            "enter time interval (## days) that you want to train your model on\n",
            "note: retrain every time you change this in the testing (analysis) cell\n",
            "4\n",
            "enter category #0\n",
            "all-assets-by-market-cap\n",
            "enter category #1\n",
            "tech\n",
            "enter category #2\n",
            "banks\n",
            "enter the \"anchor stock\" for your algorithm... just pick a stock from one of your selected categories\n",
            "refer to companiesmarketcap.com to find stock options\n",
            "gme\n",
            "no scrape\n",
            "enter your industry categories, according to the number you referrenced above\n",
            "random forest score = 0.03142857142857143\n",
            "no logistic regression\n",
            "Learning rate:  0.05\n",
            "Gradient Boosted Accuracy score (training): 0.078\n",
            "Gradient Boosted Accuracy score (validation): 0.044\n"
          ]
        }
      ],
      "source": [
        "days_back = 50\n",
        "print('enter the # of categories you would like to analyze (3 MAX)')\n",
        "num_catzz = int(input())\n",
        "## of days per return period\n",
        "xyy = {'title':[]}\n",
        "print('enter time interval (## days) that you want to train your model on')\n",
        "print('note: retrain every time you change this in the testing (analysis) cell')\n",
        "shift = int(input())\n",
        "for x in range(num_catzz):\n",
        "  print('enter category #'+str(x))\n",
        "  xyy['title'].append(str(input()).lower())\n",
        "xyy = pd.DataFrame(xyy)\n",
        "urls = [\n",
        "  'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/airlines/largest-airlines-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/airports/largest-airport-operating-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/aircraft-manufacturers/largest-aircraft-manufacturers-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/banks/largest-banks-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/hotels/largest-hotel-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/pharmaceuticals/largest-pharmaceutical-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/e-commerce/largest-e-commerce-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/healthcare/largest-healthcare-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/ports/largest-port-operating-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/professional-services/largest-professional-service-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/food/largest-food-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/restaurant-chains/largest-restaurant-chain-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/software/largest-software-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/semiconductors/largest-semiconductor-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/tobacco/largest-tobacco-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/financial-services/largest-financial-service-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/oil-gas/largest-oil-and-gas-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/electricity/largest-electricity-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/delivery-services/largest-delivery-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/media-press/largest-media-and-press-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/alcoholic-beverages/largest-alcoholic-beverage-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/beverages/largest-beverage-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/clothing/largest-clothing-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/mining/largest-mining-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/railways/largest-railways-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/insurance/largest-insurance-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/real-estate/largest-real-estate-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/chemicals/largest-chemical-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/investment/largest-investment-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/telecommunication/largest-telecommunication-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/retail/largest-retail-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/internet/largest-internet-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/construction/largest-construction-companies-by-market-cap/',\n",
        "  'https://companiesmarketcap.com/tech/largest-tech-companies-by-market-cap/'\n",
        "]\n",
        "a = []\n",
        "for x in range(len(urls)):\n",
        "    a.append(urls[x].split('/')[3])\n",
        "print('enter the \"anchor stock\" for your algorithm... just pick a stock from one of your selected categories')\n",
        "print('refer to companiesmarketcap.com to find stock options')\n",
        "ticker = input().upper()    \n",
        "\n",
        "import requests\n",
        "import time\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "cats = ['automakers','airlines','aircraft-manufacturers','banks','pharmaceuticals','e-commerce','healthcare','ports','professional-services','food','restaurant-chains','software','semiconductors','tobacco','financial-services','electricity','courier-services','media/press','alcoholic-beverages','beverages','clothing','mining','railways','insurance','real-estate','chemicals','investment','telecomunication','retail','internet','construction','tech']\n",
        "cat_names = {'category':[],'names':[],'ticker':[]}\n",
        "try:\n",
        "    for x in range(len(urls)):\n",
        "        url = urls[x]\n",
        "        html = requests.get(url).text\n",
        "        soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "        for tag in soup.findAll(\"div\", {\"class\": \"name-div\"}):\n",
        "                cat_names['names'].append(tag.findNext(\"div\").text)\n",
        "                cat_names['category'].append(a[x])\n",
        "        for tag in soup.findAll(\"div\", {\"class\": \"company-name\"}):\n",
        "                cat_names['ticker'].append(tag.findNext().text)\n",
        "\n",
        "except:\n",
        "    print(x)\n",
        "else:\n",
        "  print('no scrape')\n",
        "\n",
        "  cat_names = pd.DataFrame(cat_names)\n",
        "  print('enter your industry categories, according to the number you referrenced above')\n",
        "  gg = []  \n",
        "  tech = pd.DataFrame()\n",
        "  cat_holder = []\n",
        "  for x in range(num_catzz):\n",
        "    x = xyy['title'][x]\n",
        "    cat_holder.append(x)\n",
        "    tech = cat_names['ticker'][cat_names['category']==x]\n",
        "    gg.append(tech)\n",
        "  tech = pd.concat(gg,ignore_index = True)\n",
        "  tech = tech.drop_duplicates()\n",
        "  tickk = {'ticker':['GME']}\n",
        "  tickk = pd.DataFrame(tickk)\n",
        "  tech.append(tickk['ticker'])\n",
        "    \n",
        "\n",
        "if 1<2:\n",
        "\n",
        "  for x in range(len(tech)):\n",
        "    try: #from yfinance module (searching daily returns from tech symbols on marketcap.com)\n",
        "        xx  = yf.Ticker(tech.iloc[x])\n",
        "        df = xx.history(period=\"max\")\n",
        "        df.columns.values[0] = tech.iloc[x]+\" Open\"\n",
        "        df.columns.values[1] = tech.iloc[x]+\" High\"\n",
        "        df.columns.values[2] = tech.iloc[x]+\" Low\"\n",
        "        df.columns.values[3] = tech.iloc[x]+\" Close\"\n",
        "        df.columns.values[4] = tech.iloc[x]+\" Volume\"\n",
        "        df.columns.values[5] = tech.iloc[x]+\" Dividends\"\n",
        "        df.columns.values[6] = tech.iloc[x]+\" Stock Splits\"\n",
        "        tech.iloc[x] = df.reset_index()\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  msft = yf.Ticker(str(ticker).upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  for ii in range(len(tech)):\n",
        "    if len(tech.iloc[ii])>=days_back:\n",
        "      df = pd.merge(df, tech.iloc[ii] ,on = 'Date')\n",
        "    else:\n",
        "      print('not long enough!')\n",
        "  for x in range(num_catzz):\n",
        "    x = xyy['title'][x]\n",
        "    cat_holder.append(x)\n",
        "    tech = (cat_names['ticker'][cat_names['category']==x])\n",
        "    gg.append(tech)\n",
        "  tech = pd.concat(gg,ignore_index = True)\n",
        "  tech = tech.reset_index()\n",
        "  tech = tech.drop(columns = 'index')\n",
        "  tech = tech.drop_duplicates()\n",
        "  tech.append(tickk['ticker'])\n",
        "\n",
        "  tech = tech['ticker']\n",
        "  aa = pd.DataFrame()\n",
        "  vol = pd.DataFrame()\n",
        "  ss = []\n",
        "  for i in range(len(tech)):\n",
        "    try:\n",
        "      aa[str(tech.iloc[i])] = (df[str(tech.iloc[i])+' Close'].shift(-1*shift) - df[str(tech.iloc[i])+' Open'].shift(shift)).dropna()/df[str(tech.iloc[i])+' Open'].shift(shift).dropna()*100\n",
        "      vol[str(tech.iloc[i])] = df[str(tech.iloc[i])+' Volume']\n",
        "    except:\n",
        "      ss.append(str(tech.iloc[i]))\n",
        "  aa = round(aa)\n",
        "  tech = pd.DataFrame(tech)\n",
        "  dd = pd.DataFrame()\n",
        "  rr = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      rr[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  qq = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      qq[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  ss = []\n",
        "  df = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      df = qq.drop(columns = tech.iloc[x])\n",
        "      ss.append(df)\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  pieces = []\n",
        "  piecess = []\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      pieces.append(ss[x].iloc[-1*days_back:-1]) #for the training set\n",
        "      piecess.append(ss[x].iloc[-1*days_back:]) #the test set (using the last x iteration to predict the next return)\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  df_final = pd.concat(pieces,axis = False, ignore_index = True)\n",
        "  df_finall = pd.concat(piecess,axis= False, ignore_index = True )\n",
        "else:\n",
        "      print('no setup')\n",
        "if 2>1:\n",
        "  y = []\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      y.append(qq[tech['ticker'][x]].iloc[-1*days_back:].shift(shift*-1).dropna()) #shifting y back 1 to represent xx day(s) returns from xx day(s) returns 1 unit back\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  y = pd.concat(y, ignore_index = True)\n",
        "  yy =y.reset_index()\n",
        "  yy = yy.drop(columns = 'index')\n",
        "  yy[0].loc[~(yy[0]==0)]\n",
        "  yyy = pd.DataFrame()\n",
        "  yy = yy.dropna()\n",
        "  yyy['y'] = yy[0]\n",
        "  yyy = yyy.reset_index()\n",
        "  tt = round(df_final)\n",
        "  ttt = round(df_finall)\n",
        "  tt = tt.fillna(1)\n",
        "  ttt = ttt.fillna(1)\n",
        "  xx = tt.reset_index()\n",
        "\n",
        "  xx = xx.drop(columns = 'index')\n",
        "  xx = xx.reset_index()\n",
        "  xxx = pd.merge(yyy,xx, on = 'index')\n",
        "  y = xxx['y']\n",
        "  xxx = xxx.drop(columns = ['index','y'])\n",
        "  def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "  xxx = clean_dataset(xxx).reset_index()\n",
        "  yy = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index')\n",
        "  yy = yy['y'].astype(int)\n",
        "  xxx = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index').drop(columns = ['y','index','level_0']).astype(int)\n",
        "  x = xxx\n",
        "  xx = xxx\n",
        "  xxx = xxx\n",
        "  y = yy\n",
        "  yy = yy\n",
        "  yyy = yy\n",
        "else:\n",
        "  print('no setup')\n",
        "if 2>1:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "  clf=RandomForestClassifier(n_estimators=1000)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  print('random forest score = '+str(metrics.accuracy_score(y_test, y_pred)))\n",
        "else:\n",
        "  print('no random forest')\n",
        "if 1>2:\n",
        "  xx, yy = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "\n",
        "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  n_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "else:\n",
        "  print('no logistic regression')\n",
        "if 2>1:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(xxx, yyy, test_size=0.2)\n",
        "  lr_list = [0.05]\n",
        "  for learning_rate in lr_list:\n",
        "      gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
        "      gb_clf.fit(X_train, y_train)\n",
        "      print(\"Learning rate: \", learning_rate)\n",
        "      print(\"Gradient Boosted Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
        "      print(\"Gradient Boosted Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n",
        "else:\n",
        "  print('no gradient boosted forests')\n",
        "if 2>1:\n",
        "  xgb_clf = XGBClassifier()\n",
        "  xgb_clf.fit(X_train, y_train)\n",
        "  score = xgb_clf.score(X_test, y_test)\n",
        "  print('XGB Score = '+str(score))\n",
        "  xt = x.head(days_back)\n",
        "  yt = x.iloc[days_back:days_back][str(ticker).upper()]\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_xgb = pd.DataFrame()\n",
        "  df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "  df_compare_xgb['actual'] = yt\n",
        "  df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "  dd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "  accuracy = dd/len(df_compare_xgb)*100\n",
        "  print('xgb forest accuracy for last '+str(shift)+' '+'AAPL_test'+' '+str(accuracy))\n",
        "else:\n",
        "  print('no xg boosted forest')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bticker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "U95QbDSlyg1S",
        "outputId": "a0a82e56-e203-4637-d67d-3b862ebc6adb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GME'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "zEzbXAGgyRBG",
        "outputId": "9063fad4-3498-40af-d52b-60b98ebff607"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ticker\n",
              "0    GME"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-041ccd22-e293-4ae9-b239-f095df8b69ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GME</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-041ccd22-e293-4ae9-b239-f095df8b69ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-041ccd22-e293-4ae9-b239-f095df8b69ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-041ccd22-e293-4ae9-b239-f095df8b69ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyafcv0Bv_Q4",
        "outputId": "39f11a6f-6982-482d-ca84-50d39bee404a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         AAPL\n",
              "1         MSFT\n",
              "2         GOOG\n",
              "3         AMZN\n",
              "4         TSLA\n",
              "        ...   \n",
              "196      SWDBF\n",
              "197    1050.SR\n",
              "198        CFG\n",
              "199    2884.TW\n",
              "0          GME\n",
              "Name: ticker, Length: 201, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker['title']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "P8gq4vQDxGoF",
        "outputId": "b17106d8-a7e4-44af-9785-52f9afbbe773"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0    GME\\nName: title, dtype: object'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vchO1yI10I6L"
      },
      "outputs": [],
      "source": [
        "def option_pricing(ttt,yt,ticker,num_categories ,default, days_back,descriptive,scrape,num_trees,setup,shift_change,current_price,div,r,shift):\n",
        "  #------------------------------------------------------\n",
        "\n",
        "  #testing + graphing\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_rf = pd.DataFrame()\n",
        "  df_compare_rf['prediction'] = list(clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_rf.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  yt\n",
        "  df_compare_rf['actual'] = yt\n",
        "  df_compare_rf['dif'] = abs(df_compare_rf['actual']-df_compare_rf['prediction'])\n",
        "  dd = len(df_compare_rf[df_compare_rf['dif']==0])\n",
        "  accuracy = dd/len(df_compare_rf)*100\n",
        "  print('random forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  dd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df_ = {'open':[]}\n",
        "  for x in range(len(dd)):\n",
        "    df_['open'].append(int(dd[x]))\n",
        "  df_final = pd.DataFrame()\n",
        "  df_final[str(ticker.upper())+' prediction'] = df_['open'] + df_compare_rf['prediction']/100*df_['open']\n",
        "  y1 = df_final[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_xgb = pd.DataFrame()\n",
        "  df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_xgb.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  df_compare_xgb['actual'] = yt\n",
        "  df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "  ddd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "  accuracyy = ddd/len(df_compare_xgb)*100\n",
        "  print('xgb forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracyy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  ddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df__ = {'open':[]}\n",
        "  for x in range(len(ddd)):\n",
        "    df__['open'].append(int(ddd[x]))\n",
        "  df_final_xgb = pd.DataFrame()\n",
        "  df_final_xgb[str(ticker.upper())+' prediction'] = df__['open'] + df_compare_xgb['prediction']/100*df__['open']\n",
        "  x11 = df_final_xgb[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_gb = pd.DataFrame()\n",
        "  df_compare_gb['prediction'] = list(gb_clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_gb.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  df_compare_gb['actual'] = yt\n",
        "  df_compare_gb['dif'] = abs(df_compare_gb['actual']-df_compare_gb['prediction'])\n",
        "  dddd = len(df_compare_gb[df_compare_gb['dif']==0])\n",
        "  accuracyyy = dddd/len(df_compare_gb)*100\n",
        "  print('gb forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracyyy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  dddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df___ = {'open':[]}\n",
        "  for x in range(len(dddd)):\n",
        "    df___['open'].append(int(dddd[x]))\n",
        "  df_finalll = pd.DataFrame()\n",
        "  df_finalll[str(ticker.upper())+' prediction'] = df___['open'] + df_compare_gb['prediction']/100*df___['open']\n",
        "  x111 = df_finalll[str(ticker.upper())+' prediction']\n",
        "\n",
        "  df_check = pd.DataFrame()\n",
        "  df_check['rf'] = y1\n",
        "  df_check['gb'] = x111\n",
        "  df_check['xgb'] = x11\n",
        "  df_check['actual'] = dd.reset_index().drop(columns = ['Date']).head(days_back)\n",
        "\n",
        "  plt.figure(figsize = (20, 10))\n",
        "  ax = y1.head(days_back).plot(label='rf prediction')\n",
        "  ax = (df_['open'] + df_compare_rf['actual']/100*df_['open']).plot(label='Actual')\n",
        "  ax = x11.head(days_back).plot(label='xgb prediction')\n",
        "  ax = x111.head(days_back).plot(label='gb prediction')\n",
        "  ax.set_xlabel('Date')\n",
        "  ax.set_ylabel(str(ticker.upper()))\n",
        "  plt.axvline(x = days_back-1, color = 'b', label = 'axvline - full height')\n",
        "\n",
        "  leg = plt.legend()\n",
        "  for line in leg.get_lines():\n",
        "      line.set_linewidth(10)\n",
        "  for text in leg.get_texts():\n",
        "      text.set_fontsize('x-large')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig('predictions plot for '+str(ticker.upper())+'.png')\n",
        "\n",
        "  print(df_check)\n",
        "\n",
        "  def options_chain(symbol):\n",
        "      msft = yf.Ticker(symbol)\n",
        "      exps = msft.options\n",
        "      ops = pd.DataFrame()\n",
        "      for e in exps:\n",
        "          opt = msft.option_chain(e)\n",
        "          opt = pd.DataFrame().append(opt.calls).append(opt.puts)\n",
        "          opt['expirationDate'] = e\n",
        "          ops = ops.append(opt, ignore_index=True)\n",
        "      ops['expirationDate'] = pd.to_datetime(ops['expirationDate']) + timedelta(days = 1)\n",
        "      ops['dte'] = (ops['expirationDate'] - datetime.today()).dt.days\n",
        "      ops['CALL'] = ops['contractSymbol'].str[0:].apply(\n",
        "          lambda x: \"C\" in x)\n",
        "      ops[['bid', 'ask', 'strike']] = ops[['bid', 'ask', 'strike']].apply(pd.to_numeric)\n",
        "      ops['mark'] = (ops['bid'] + ops['ask']) / 2*1000\n",
        "      return ops\n",
        "\n",
        "  df = options_chain(str(ticker.upper())).sort_values('dte',ascending=True)\n",
        "\n",
        "  calls = df[df['CALL']==True]\n",
        "  puts = df[df['CALL']==False]\n",
        "  puts = puts.sort_values('expirationDate',ascending = True)\n",
        "  calls = calls.sort_values('expirationDate',ascending = True)\n",
        "\n",
        "  #black scholes formula\n",
        "  def d1(S,K,T,r,div,sigma):\n",
        "      return(log(S/K)+(r-div+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "  def d2(S,K,T,r,div,sigma):\n",
        "      return d1(S,K,T,r,div,sigma)-sigma*sqrt(T)\n",
        "  def bs_call(S,K,T,r,div,sigma):\n",
        "      return S*norm.cdf(d1(S,K,T,r,div,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,div,sigma))\n",
        "  def bs_put(S,K,T,r,div,sigma):\n",
        "      return K*exp(-r*T)-S+bs_call(S,K,T,r,div,sigma)\n",
        "  print('puts:')\n",
        "  S = current_price\n",
        "  S1 =  float((df_['open'] + df_compare_rf['actual']/100*df_['open']).drop(columns = 'index')[days_back])\n",
        "  difference = S1 - S\n",
        "  pdifference = difference/S\n",
        "\n",
        "  try:\n",
        "    Tp = float(puts['dte'].reset_index().drop(columns = 'index')['dte'][xxe])/365\n",
        "    Kp = float(puts['strike'].reset_index().drop(columns = 'index')['strike'][xxe])\n",
        "    sigmap = float(puts['impliedVolatility'].reset_index().drop(columns = 'index')['impliedVolatility'][xxe])\n",
        "    \n",
        "    #FORMULA: C = price*N( [ln(price/strike)+interest_rate-divYield+vol^2/2)*T]/(vol*sqrt(T)) ] - strike*e^(interest rate * time)*N(d1 - vol*sqrt(T))\n",
        "    print('Black Scholes Results...')\n",
        "    zvvv = str(float((puts['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+puts['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('Price of put: '+zvvv)\n",
        "    zvv = str(Kp-current_price-float((puts['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+puts['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('\"immdiate excercise value\" of put:'+zvv)\n",
        "    zv = str(bs_put(S,Kp,Tp,r,div,sigmap))\n",
        "    print('Black-Scholes expected value of put(from stock open today): '+zv)\n",
        "    zzv = str(Tp)[:4]+' day(s): '+str(bs_put(S1,Kp,Tp,r,div,sigmap))\n",
        "    print('Value of put according to avg of ensemble predictsions in '+zzv)\n",
        "    print(' ---------- ')\n",
        "  except:\n",
        "    print('no puts for '+str(ticker.upper()))\n",
        "  print(' ---------- ')\n",
        "  print('calls:')\n",
        "  try:\n",
        "    Tc = float(calls['dte'].reset_index().drop(columns = 'index')['dte'][xxe])/365\n",
        "    Kc = float(calls['strike'].reset_index().drop(columns = 'index')['strike'][xxe])\n",
        "    sigmac = float(calls['impliedVolatility'].reset_index().drop(columns = 'index')['impliedVolatility'][xxe])\n",
        "    cvvv = str(float((calls['bid'].reset_index().drop(columns = 'index')['bid'][x])+calls['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('Price of call: '+cvvv)\n",
        "    cvv = str(current_price-Kc-float((calls['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+calls['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('\"immdiate excercise value\" of call:'+cvv)\n",
        "    cv = str(bs_call(S,Kc,Tc,r,div,sigmac))\n",
        "    print('Black-Scholes expected value of call(from stock open today): '+cv)\n",
        "    ccv = str(Tc)[:]+' day(s): '+str(bs_call(S1,Kc,Tc,r,div,sigmac))\n",
        "    print('Value of call according to avg of ensemble predictsions in '+ccv)\n",
        "  except:\n",
        "    print('no calls for '+str(ticker.upper()))\n",
        "  \n",
        "  return ticker, cvvv, cvv, cv,ccv, zvvv, zvv, zv,zzv, S1, difference, pdifference\n",
        "       # ticker, price of call, immediate excercise value call, BS value, BS pred value, same for put, PRED_PRICE, PRED DIF, PRED P%\n",
        "xcer =0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PyZD8cr7KuL"
      },
      "source": [
        "\n",
        "**Running Multiple Predictions...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "uNqHNP9r23X2",
        "outputId": "d0143c81-35c2-4445-ddbc-5bef6d67eaee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shift is set to 4 --> 4 day returns (go to very top of this cell and change if you want to predict sooner / farhther out (option pricing only works for 4 right now)\n",
            "already trained\n",
            ">1 predictions\n",
            "enter the # of stocks you would like to analyze\n",
            "1\n",
            "enter stock symbol for the 0th stock that you would like to analyze\n",
            "gme\n",
            "enter the price for your 0th stock\n",
            "146.93\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-2071d1d5bb64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mxz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0mttt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mgg_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moption_pricing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mttt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_catzz\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdays_back\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdescriptive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscrape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_trees\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshift_change\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurrent_price\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m   \u001b[0mresultz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mresultz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgg_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'yt' is not defined"
          ]
        }
      ],
      "source": [
        "#default\n",
        "num_categories = 3\n",
        "xxe = 0\n",
        "shift = xxe + 4\n",
        "r = 0.02353\n",
        "div = 0\n",
        "days_back = 50\n",
        "num_trees = 1000\n",
        "start_date = '2021-09-03'\n",
        "descriptive = 'yes'\n",
        "cat_change = 'afdsa'\n",
        "\n",
        "print('shift is set to 4 --> 4 day returns (go to very top of this cell and change if you want to predict sooner / farhther out (option pricing only works for 4 right now)')\n",
        "\n",
        "if cat_change == 'faasd':\n",
        "  #if you want to change cats\n",
        "  scrape = 'yes'\n",
        "  num_trees = 1000\n",
        "  setup = 'on'\n",
        "  default = 'on'\n",
        "  shift_change = 'on'\n",
        "  random_forest = 'yes'\n",
        "  xgb = 'yes'\n",
        "  logi_regression = 'no'\n",
        "  gradient_boosted = 'yes'\n",
        "  print('not trained')\n",
        "else:\n",
        "  #already trained model on cats\n",
        "  num_trees = 1000\n",
        "  scrape = 'no'\n",
        "  setup = 'off'\n",
        "  default = 'on'\n",
        "  shift_change = 'off'\n",
        "  random_forest = 'off'\n",
        "  xgb = 'off'\n",
        "  logi_regression = 'off'\n",
        "  gradient_boosted = 'off'\n",
        "  print('already trained')\n",
        "\n",
        "  xcx = 'afdsa'\n",
        "  xyy = xyy\n",
        "\n",
        "  select_group = \"group\"\n",
        "\n",
        "\n",
        "  if select_group =='single':\n",
        "    print('enter the # of stocks you would like to analyze')\n",
        "    num_preds = int(input())\n",
        "    current_price = {'title':[]}\n",
        "    ticker = {'title':[]}\n",
        "    ticker = pd.DataFrame(ticker)\n",
        "    current_price = pd.DataFrame(current_price)\n",
        "\n",
        "    for x in range(num_preds):\n",
        "      print('enter stock symbol for the '+str(x)+'th stock that you would like to analyze')\n",
        "      ticker['title'].append(str(input().upper()))\n",
        "      print('enter the price for your '+str(x)+'th stock')\n",
        "      current_price['title'].append(float(input()))\n",
        "  else:\n",
        "    print('>1 predictions')\n",
        "\n",
        "  if select_group =='group':  \n",
        "    print('enter the # of stocks you would like to analyze')\n",
        "    num_preds = int(input())\n",
        "    current_price = {'title':[]}\n",
        "    ticker = {'title':[]}\n",
        "    \n",
        "    for x in range(num_preds):\n",
        "      print('enter stock symbol for the '+str(x)+'th stock that you would like to analyze')\n",
        "      ticker['title'].append(str(input().upper()))\n",
        "      print('enter the price for your '+str(x)+'th stock')\n",
        "      current_price['title'].append(float(input()))\n",
        "    ticker = pd.DataFrame(ticker)\n",
        "    current_price = pd.DataFrame(current_price)\n",
        "\n",
        "  else:\n",
        "    print('not a select group')\n",
        "\n",
        "  gg_ = pd.DataFrame()\n",
        "  for xz in range(num_preds):\n",
        "      ttt = ttt\n",
        "      gg_[str(ticker['title'][xz])] = option_pricing(ttt,yt,ticker['title'][xz],num_catzz ,default, days_back,descriptive,scrape,num_trees,setup,shift_change,current_price['title'][xz],div,r,shift)\n",
        "  resultz = pd.DataFrame()\n",
        "  resultz['ticker'] = gg_.iloc[0]\n",
        "  resultz['callPrice'] = gg_.iloc[1]\n",
        "  resultz['immediateExcerciseCallValue'] = gg_.iloc[2]\n",
        "  resultz['callBScholes'] = gg_.iloc[3]\n",
        "  resultz['callBScholesPred'] = gg_.iloc[4]\n",
        "  resultz['putPrice'] = gg_.iloc[5]\n",
        "  resultz['immediateExcercisePutValue'] = gg_.iloc[6]\n",
        "  resultz['putBScholes'] = gg_.iloc[7]\n",
        "  resultz['putBScholesPred'] = gg_.iloc[8]\n",
        "  resultz['predictedPrice'] = gg_.iloc[9]\n",
        "  resultz['predicted%Change'] = gg_.iloc[10]\n",
        " # price of call, immediate excercise value call, BS value, BS pred value, same for put, PRED_PRICE, PRED DIF, PRED P%\n",
        "resultz.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6f1UX5qLfZ-"
      },
      "source": [
        "**Just prediction / chart**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZRpaAsFHe1x",
        "outputId": "4f997736-28e5-4d6f-867c-262ca85f0d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default (on/off)\n",
            "       * specs: up to 3 categories, you choose ticker+forecast period, 2k trees, trained on last 50 days of each stock's returns!\n",
            "on\n",
            "input ticker\n",
            "coin\n",
            "model will predict xx days into the future\n",
            "0\n",
            "run a random forest: (yes/no)\n",
            "yes\n",
            "run a xgboost (yes/no):\n",
            "yes\n",
            "run a logit (yes/no):\n",
            "no\n",
            "run a gradient boosted (yes/no):\n",
            "yes\n",
            "enter your industry categories, according to the number you referrenced above\n",
            "tech\n",
            "software\n",
            "internet\n",
            "MCHP\n",
            "ANSS\n",
            "PATH\n",
            "FICO\n",
            "NEM.F\n",
            "AZPN\n",
            "HCP\n",
            "AVV.L\n",
            "SGE.L\n",
            "4716.T\n",
            "IOT\n",
            "FIVN\n",
            "SMAR\n",
            "IBKR\n",
            "377300.KS\n",
            "DHER.F\n",
            "BILI\n",
            "W\n"
          ]
        }
      ],
      "source": [
        "from bs4.element import DEFAULT_OUTPUT_ENCODING\n",
        "print('default (on/off)')\n",
        "print(\"       * specs: up to 3 categories, you choose ticker+forecast period, 2k trees, trained on last 50 days of each stock's returns!\")\n",
        "default = input().lower()\n",
        "print('input ticker')\n",
        "ticker = input().upper()\n",
        "print('model will predict xx days into the future')\n",
        "shift = int(input())\n",
        "\n",
        "if default == 'on':\n",
        "  num_categories = 3\n",
        "  days_back = 50\n",
        "  descriptive = 'yes'\n",
        "  scrape = 'yes'\n",
        "  num_trees = 2000\n",
        "  setup = 'on'\n",
        "  shift_change = 'on'\n",
        "  start_date = '2021-09-03'\n",
        "else:\n",
        "  print('Enter the # of stock \"categories\" you would like to include')\n",
        "  print('      *ensure that the ticker you want to predict is in this category')\n",
        "  print('      *(find categories @ companiesmarketcap.com)')\n",
        "  print()\n",
        "  print('      *3 categories max! (bug)')\n",
        "  num_categories = int(input())\n",
        "  descriptive = 'bugged'\n",
        "  print('the stocks in your selected categories will be stacked on top of each other for training purposes, how many days back would you like each stock to go? (i.e. 10 days: 10 days of past returns for each stock):')\n",
        "  days_back = int(input())\n",
        "  print('how many trees do you want the random forest to have?:')\n",
        "  num_trees = int(input())\n",
        "  print('Do you need to scrape companymarketcap.com (yes/no) (only need to do once / runtime):')\n",
        "  scrape = input()\n",
        "  print('For each stock, we are predicting returns xx days into the future. How many days would you like to lag your data:')\n",
        "  shift = int(input())\n",
        "  start_date = '2021-09-03'\n",
        "  print('yahoo finance data collection (on/off) (every time you change category selection):')\n",
        "  setup = input()\n",
        "  print('Quick setup (on/off):')\n",
        "  shift_change = input()\n",
        "\n",
        "print('run a random forest: (yes/no)')\n",
        "random_forest = input()\n",
        "print('run a xgboost (yes/no):')\n",
        "xgb = input()\n",
        "print('run a logit (yes/no):')\n",
        "logi_regression = input()\n",
        "print('run a gradient boosted (yes/no):')\n",
        "gradient_boosted = input()\n",
        "\n",
        "#------------------------------------------------------\n",
        "\n",
        "if scrape == 'yes':\n",
        "  urls = [\n",
        "    'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/airlines/largest-airlines-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/airports/largest-airport-operating-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/aircraft-manufacturers/largest-aircraft-manufacturers-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/banks/largest-banks-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/hotels/largest-hotel-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/pharmaceuticals/largest-pharmaceutical-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/e-commerce/largest-e-commerce-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/healthcare/largest-healthcare-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/ports/largest-port-operating-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/professional-services/largest-professional-service-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/food/largest-food-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/restaurant-chains/largest-restaurant-chain-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/software/largest-software-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/semiconductors/largest-semiconductor-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/tobacco/largest-tobacco-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/financial-services/largest-financial-service-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/oil-gas/largest-oil-and-gas-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/electricity/largest-electricity-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/delivery-services/largest-delivery-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/media-press/largest-media-and-press-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/alcoholic-beverages/largest-alcoholic-beverage-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/beverages/largest-beverage-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/clothing/largest-clothing-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/mining/largest-mining-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/railways/largest-railways-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/insurance/largest-insurance-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/real-estate/largest-real-estate-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/chemicals/largest-chemical-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/investment/largest-investment-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/telecommunication/largest-telecommunication-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/retail/largest-retail-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/internet/largest-internet-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/construction/largest-construction-companies-by-market-cap/',\n",
        "    'https://companiesmarketcap.com/tech/largest-tech-companies-by-market-cap/'\n",
        "  ]\n",
        "  a = []\n",
        "  for x in range(len(urls)):\n",
        "      a.append(urls[x].split('/')[3])\n",
        "\n",
        "  import requests\n",
        "  import time\n",
        "  import bs4\n",
        "  from bs4 import BeautifulSoup\n",
        "  cats = ['automakers','airlines','aircraft-manufacturers','banks','pharmaceuticals','e-commerce','healthcare','ports','professional-services','food','restaurant-chains','software','semiconductors','tobacco','financial-services','electricity','courier-services','media/press','alcoholic-beverages','beverages','clothing','mining','railways','insurance','real-estate','chemicals','investment','telecomunication','retail','internet','construction','tech']\n",
        "  cat_names = {'category':[],'names':[],'ticker':[]}\n",
        "  try:\n",
        "      for x in range(len(urls)):\n",
        "          url = urls[x]\n",
        "          html = requests.get(url).text\n",
        "          soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "          for tag in soup.findAll(\"div\", {\"class\": \"name-div\"}):\n",
        "                  cat_names['names'].append(tag.findNext(\"div\").text)\n",
        "                  cat_names['category'].append(a[x])\n",
        "          for tag in soup.findAll(\"div\", {\"class\": \"company-name\"}):\n",
        "                  cat_names['ticker'].append(tag.findNext().text)\n",
        "\n",
        "  except:\n",
        "      print(x)\n",
        "else:\n",
        "  print('no scrape')\n",
        "\n",
        "if setup == 'on':\n",
        "  cat_names = pd.DataFrame(cat_names)\n",
        "  print('enter your industry categories, according to the number you referrenced above')\n",
        "  gg = []  \n",
        "  tech = pd.DataFrame()\n",
        "  cat_holder = []\n",
        "  for x in range(num_categories):\n",
        "    x = input()\n",
        "    cat_holder.append(x)\n",
        "    tech = (cat_names['ticker'][cat_names['category']==x])\n",
        "    gg.append(tech)\n",
        "  tech = pd.concat(gg,ignore_index = True)\n",
        "  tech = tech.drop_duplicates()\n",
        "    \n",
        "\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "        xx  = yf.Ticker(tech.iloc[x])\n",
        "        df = xx.history(period=\"max\")\n",
        "        df.columns.values[0] = tech.iloc[x]+\" Open\"\n",
        "        df.columns.values[1] = tech.iloc[x]+\" High\"\n",
        "        df.columns.values[2] = tech.iloc[x]+\" Low\"\n",
        "        df.columns.values[3] = tech.iloc[x]+\" Close\"\n",
        "        df.columns.values[4] = tech.iloc[x]+\" Volume\"\n",
        "        df.columns.values[5] = tech.iloc[x]+\" Dividends\"\n",
        "        df.columns.values[6] = tech.iloc[x]+\" Stock Splits\"\n",
        "        tech.iloc[x] = df.reset_index()\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  for ii in range(len(tech)):\n",
        "    if len(tech.iloc[ii])>=days_back:\n",
        "      df = pd.merge(df, tech.iloc[ii] ,on = 'Date')\n",
        "    else:\n",
        "      print('not long enough!')\n",
        "  for x in range(num_categories):\n",
        "    tech = (cat_names['ticker'][cat_names['category']==pd.DataFrame(cat_holder)[0][x]])\n",
        "    gg.append(tech)\n",
        "  tech = pd.concat(gg,ignore_index = True)\n",
        "  tech = tech.reset_index()\n",
        "  tech = tech.drop(columns = 'index')\n",
        "  tech = tech.drop_duplicates()\n",
        "  tech = tech['ticker']\n",
        "  aa = pd.DataFrame()\n",
        "  vol = pd.DataFrame()\n",
        "  ss = []\n",
        "  for i in range(len(tech)):\n",
        "    try:\n",
        "      aa[str(tech.iloc[i])] = (df[str(tech.iloc[i])+' Close'].shift(-1*shift) - df[str(tech.iloc[i])+' Open'].shift(shift)).dropna()/df[str(tech.iloc[i])+' Open'].shift(shift).dropna()*100\n",
        "      vol[str(tech.iloc[i])] = df[str(tech.iloc[i])+' Volume']\n",
        "    except:\n",
        "      ss.append(str(tech.iloc[i]))\n",
        "  aa = round(aa)\n",
        "  tech = pd.DataFrame(tech)\n",
        "  dd = pd.DataFrame()\n",
        "  rr = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      rr[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  qq = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      qq[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  ss = []\n",
        "  df = pd.DataFrame()\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      df = qq.drop(columns = tech.iloc[x])\n",
        "      ss.append(df)\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  pieces = []\n",
        "  piecess = []\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      pieces.append(ss[x].iloc[-1*days_back:-1])\n",
        "      piecess.append(ss[x].iloc[-1*days_back:])\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  df_final = pd.concat(pieces,axis = False, ignore_index = True)\n",
        "  df_finall = pd.concat(pieces,axis= False, ignore_index = True )\n",
        "else:\n",
        "      print('no setup')\n",
        "if shift_change == 'on':\n",
        "  y = []\n",
        "  for x in range(len(tech)):\n",
        "    try:\n",
        "      y.append(qq[tech['ticker'][x]].iloc[-1*days_back:].shift(shift*-1).dropna())\n",
        "    except:\n",
        "      print(tech.iloc[x])\n",
        "  y = pd.concat(y, ignore_index = True)\n",
        "  yy =y.reset_index()\n",
        "  yy = yy.drop(columns = 'index')\n",
        "  yy[0].loc[~(yy[0]==0)]\n",
        "  yyy = pd.DataFrame()\n",
        "  yy = yy.dropna()\n",
        "  yyy['y'] = yy[0]\n",
        "  yyy = yyy.reset_index()\n",
        "  tt = round(df_final)\n",
        "  ttt = round(df_finall)\n",
        "  tt = tt.fillna(1)\n",
        "  ttt = ttt.fillna(1)\n",
        "  xx = tt.reset_index()\n",
        "\n",
        "  xx = xx.drop(columns = 'index')\n",
        "  xx = xx.reset_index()\n",
        "  xxx = pd.merge(yyy,xx, on = 'index')\n",
        "  y = xxx['y']\n",
        "  xxx = xxx.drop(columns = ['index','y'])\n",
        "  def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "  xxx = clean_dataset(xxx).reset_index()\n",
        "  yy = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index')\n",
        "  yy = yy['y'].astype(int)\n",
        "  xxx = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index').drop(columns = ['y','index','level_0']).astype(int)\n",
        "  x = xxx\n",
        "  xx = xxx\n",
        "  xxx = xxx\n",
        "  y = yy\n",
        "  yy = yy\n",
        "  yyy = yy\n",
        "else:\n",
        "  print('no setup')\n",
        "if random_forest == 'yes':\n",
        "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "  clf=RandomForestClassifier(n_estimators=num_trees)\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  print('random forest score = '+str(metrics.accuracy_score(y_test, y_pred)))\n",
        "else:\n",
        "  print('no random forest')\n",
        "if logi_regression == 'yes':\n",
        "  xx, yy = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "\n",
        "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  n_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "else:\n",
        "  print('no logistic regression')\n",
        "if gradient_boosted == 'yes':\n",
        "  X_train, X_test, y_train, y_test = train_test_split(xxx, yyy, test_size=0.2)\n",
        "  lr_list = [0.05, 0.075, 0.1]\n",
        "  for learning_rate in lr_list:\n",
        "      gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
        "      gb_clf.fit(X_train, y_train)\n",
        "      print(\"Learning rate: \", learning_rate)\n",
        "      print(\"Gradient Boosted Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
        "      print(\"Gradient Boosted Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n",
        "else:\n",
        "  print('no gradient boosted forests')\n",
        "if xgb == 'yes':\n",
        "  xgb_clf = XGBClassifier()\n",
        "  xgb_clf.fit(X_train, y_train)\n",
        "  score = xgb_clf.score(X_test, y_test)\n",
        "  print('XGB Score = '+str(score))\n",
        "  xt = x.head(days_back)\n",
        "  yt = x.iloc[days_back:days_back][ticker.upper()]\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_xgb = pd.DataFrame()\n",
        "  df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "  df_compare_xgb['actual'] = yt\n",
        "  df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "  dd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "  accuracy = dd/len(df_compare_xgb)*100\n",
        "  print('xgb forest accuracy for last '+str(shift)+' '+ticker+' '+str(accuracy))\n",
        "else:\n",
        "  print('no xg boosted forest')\n",
        "\n",
        "#testing + graphing\n",
        "xt = ttt.head(days_back+1)\n",
        "yt = yt.reset_index().drop(columns = 'index')\n",
        "df_compare_rf = pd.DataFrame()\n",
        "df_compare_rf['prediction'] = list(clf.predict(xt))\n",
        "yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_rf.mean()[-1:])\n",
        "yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "yt\n",
        "df_compare_rf['actual'] = yt\n",
        "df_compare_rf['dif'] = abs(df_compare_rf['actual']-df_compare_rf['prediction'])\n",
        "dd = len(df_compare_rf[df_compare_rf['dif']==0])\n",
        "accuracy = dd/len(df_compare_rf)*100\n",
        "print('random forest accuracy for last '+str(shift)+' '+ticker+' '+str(accuracy))\n",
        "msft = yf.Ticker(ticker.upper())\n",
        "df = msft.history(period=\"max\")\n",
        "dd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "df_ = {'open':[]}\n",
        "for x in range(len(dd)):\n",
        "  df_['open'].append(int(dd[x]))\n",
        "df_final = pd.DataFrame()\n",
        "df_final[str(ticker.upper())+' prediction'] = df_['open'] + df_compare_rf['prediction']/100*df_['open']\n",
        "y1 = df_final[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "xt = ttt.head(days_back+1)\n",
        "yt = yt.reset_index().drop(columns = 'index')\n",
        "df_compare_xgb = pd.DataFrame()\n",
        "df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_xgb.mean()[-1:])\n",
        "yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "df_compare_xgb['actual'] = yt\n",
        "df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "ddd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "accuracyy = ddd/len(df_compare_xgb)*100\n",
        "print('xgb forest accuracy for last '+str(shift)+' '+ticker+' '+str(accuracyy))\n",
        "msft = yf.Ticker(ticker.upper())\n",
        "df = msft.history(period=\"max\")\n",
        "ddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "df__ = {'open':[]}\n",
        "for x in range(len(ddd)):\n",
        "  df__['open'].append(int(ddd[x]))\n",
        "df_final_xgb = pd.DataFrame()\n",
        "df_final_xgb[str(ticker.upper())+' prediction'] = df__['open'] + df_compare_xgb['prediction']/100*df__['open']\n",
        "x11 = df_final_xgb[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "xt = ttt.head(days_back+1)\n",
        "yt = yt.reset_index().drop(columns = 'index')\n",
        "df_compare_gb = pd.DataFrame()\n",
        "df_compare_gb['prediction'] = list(gb_clf.predict(xt))\n",
        "yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_gb.mean()[-1:])\n",
        "yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "df_compare_gb['actual'] = yt\n",
        "df_compare_gb['dif'] = abs(df_compare_gb['actual']-df_compare_gb['prediction'])\n",
        "dddd = len(df_compare_gb[df_compare_gb['dif']==0])\n",
        "accuracyyy = dddd/len(df_compare_gb)*100\n",
        "print('gb forest accuracy for last '+str(shift)+' '+ticker+' '+str(accuracyyy))\n",
        "msft = yf.Ticker(ticker.upper())\n",
        "df = msft.history(period=\"max\")\n",
        "dddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "df___ = {'open':[]}\n",
        "for x in range(len(dddd)):\n",
        "  df___['open'].append(int(dddd[x]))\n",
        "df_finalll = pd.DataFrame()\n",
        "df_finalll[str(ticker.upper())+' prediction'] = df___['open'] + df_compare_gb['prediction']/100*df___['open']\n",
        "x111 = df_finalll[str(ticker.upper())+' prediction']\n",
        "\n",
        "df_check = pd.DataFrame()\n",
        "df_check['rf'] = y1\n",
        "df_check['gb'] = x111\n",
        "df_check['xgb'] = x11\n",
        "df_check['actual'] = dd.reset_index().drop(columns = ['Date']).head(days_back)\n",
        "\n",
        "plt.figure(figsize = (20, 10))\n",
        "ax = y1.head(days_back).plot(label='rf prediction')\n",
        "ax = (df_['open'] + df_compare_rf['actual']/100*df_['open']).plot(label='Actual')\n",
        "ax = x11.head(days_back).plot(label='xgb prediction')\n",
        "ax = x111.head(days_back).plot(label='gb prediction')\n",
        "ax.set_xlabel('Date')\n",
        "ax.set_ylabel(str(ticker.upper()))\n",
        "plt.axvline(x = days_back-1, color = 'b', label = 'axvline - full height')\n",
        "\n",
        "leg = plt.legend()\n",
        "for line in leg.get_lines():\n",
        "    line.set_linewidth(10)\n",
        "for text in leg.get_texts():\n",
        "    text.set_fontsize('x-large')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "df_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9r5dFGf8di_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCtHjXX58dmC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIk3ZjPY8dof"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdau7-lL8eL2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHSfiNjX8eOv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM8axhm58eR_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J2SsW4D8T9V"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmYKi5f3Ovs0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "\n",
        "time.sleep(60)\n",
        "consumer_key= '7d7PKS74mTCa5EYGc6lw5KHyH'\n",
        "consumer_secret= 'FG2d31TVlPaR7zTedvsQUX9vkC5c4tInorAOPIdJ0nMNT2GqmP'\n",
        "access_token= '1343573569796767745-TDUJmh3IEyPIY390WkW1N10b9uBPZG'\n",
        "access_token_secret= '1PQ1MuLQtm82v6ML9ks908J75xvppFFkn1kH3cd4yLTyA'\n",
        "\n",
        "\n",
        "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "search_words = '#$TSLA'\n",
        "search = search_words + \" -filter:retweets\"\n",
        "\n",
        "\n",
        "tweets = tw.Cursor(api.search,\n",
        "                    q=search,\n",
        "                    lang=\"en\",\n",
        "                    since='2022-01-01').items(1000)\n",
        "\n",
        "\n",
        "all_tweets = [[tweet.text, tweet.id, str(tweet.created_at.date()),tweet.user.location,tweet.entities] for tweet in tweets]\n",
        "\n",
        "df = pd.DataFrame(all_tweets)"
      ],
      "metadata": {
        "id": "GeB9ScEq-p8U"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qVMnyGfQ2SW"
      },
      "outputs": [],
      "source": [
        "def option_pricing(ticker,num_categories ,default, days_back,descriptive,scrape,num_trees,setup,shift_change,current_price,div,r,shift):\n",
        "  #------------------------------------------------------\n",
        "  if scrape == 'yes':\n",
        "    urls = [\n",
        "      'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/automakers/largest-automakers-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/airlines/largest-airlines-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/airports/largest-airport-operating-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/aircraft-manufacturers/largest-aircraft-manufacturers-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/banks/largest-banks-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/hotels/largest-hotel-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/pharmaceuticals/largest-pharmaceutical-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/e-commerce/largest-e-commerce-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/healthcare/largest-healthcare-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/ports/largest-port-operating-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/professional-services/largest-professional-service-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/food/largest-food-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/restaurant-chains/largest-restaurant-chain-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/software/largest-software-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/semiconductors/largest-semiconductor-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/tobacco/largest-tobacco-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/financial-services/largest-financial-service-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/oil-gas/largest-oil-and-gas-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/electricity/largest-electricity-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/delivery-services/largest-delivery-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/media-press/largest-media-and-press-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/alcoholic-beverages/largest-alcoholic-beverage-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/beverages/largest-beverage-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/clothing/largest-clothing-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/mining/largest-mining-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/railways/largest-railways-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/insurance/largest-insurance-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/real-estate/largest-real-estate-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/chemicals/largest-chemical-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/investment/largest-investment-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/telecommunication/largest-telecommunication-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/retail/largest-retail-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/internet/largest-internet-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/construction/largest-construction-companies-by-market-cap/',\n",
        "      'https://companiesmarketcap.com/tech/largest-tech-companies-by-market-cap/'\n",
        "    ]\n",
        "    a = []\n",
        "    for x in range(len(urls)):\n",
        "        a.append(urls[x].split('/')[3])\n",
        "\n",
        "    import requests\n",
        "    import time\n",
        "    import bs4\n",
        "    from bs4 import BeautifulSoup\n",
        "    cats = ['automakers','airlines','aircraft-manufacturers','banks','pharmaceuticals','e-commerce','healthcare','ports','professional-services','food','restaurant-chains','software','semiconductors','tobacco','financial-services','electricity','courier-services','media/press','alcoholic-beverages','beverages','clothing','mining','railways','insurance','real-estate','chemicals','investment','telecomunication','retail','internet','construction','tech']\n",
        "    cat_names = {'category':[],'names':[],'ticker':[]}\n",
        "    try:\n",
        "        for x in range(len(urls)):\n",
        "            url = urls[x]\n",
        "            html = requests.get(url).text\n",
        "            soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
        "            for tag in soup.findAll(\"div\", {\"class\": \"name-div\"}):\n",
        "                    cat_names['names'].append(tag.findNext(\"div\").text)\n",
        "                    cat_names['category'].append(a[x])\n",
        "            for tag in soup.findAll(\"div\", {\"class\": \"company-name\"}):\n",
        "                    cat_names['ticker'].append(tag.findNext().text)\n",
        "\n",
        "    except:\n",
        "        print(x)\n",
        "  else:\n",
        "    print('no scrape')\n",
        "\n",
        "  if setup == 'on':\n",
        "    cat_names = pd.DataFrame(cat_names)\n",
        "    print('enter your industry categories, according to the number you referrenced above')\n",
        "    gg = []  \n",
        "    tech = pd.DataFrame()\n",
        "    cat_holder = []\n",
        "    for x in range(num_catzz):\n",
        "      x = xyy['title'][x]\n",
        "      cat_holder.append(x)\n",
        "      tech = (cat_names['ticker'][cat_names['category']==x])\n",
        "      gg.append(tech)\n",
        "    tech = pd.concat(gg,ignore_index = True)\n",
        "    tech = tech.drop_duplicates()\n",
        "      \n",
        "\n",
        "    for x in range(len(tech)):\n",
        "      try: #from yfinance module (searching daily returns from tech symbols on marketcap.com)\n",
        "          xx  = yf.Ticker(tech.iloc[x])\n",
        "          df = xx.history(period=\"max\")\n",
        "          df.columns.values[0] = tech.iloc[x]+\" Open\"\n",
        "          df.columns.values[1] = tech.iloc[x]+\" High\"\n",
        "          df.columns.values[2] = tech.iloc[x]+\" Low\"\n",
        "          df.columns.values[3] = tech.iloc[x]+\" Close\"\n",
        "          df.columns.values[4] = tech.iloc[x]+\" Volume\"\n",
        "          df.columns.values[5] = tech.iloc[x]+\" Dividends\"\n",
        "          df.columns.values[6] = tech.iloc[x]+\" Stock Splits\"\n",
        "          tech.iloc[x] = df.reset_index()\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "\n",
        "    msft = yf.Ticker(ticker.upper())\n",
        "    df = msft.history(period=\"max\")\n",
        "    for ii in range(len(tech)):\n",
        "      if len(tech.iloc[ii])>=days_back:\n",
        "        df = pd.merge(df, tech.iloc[ii] ,on = 'Date')\n",
        "      else:\n",
        "        print('not long enough!')\n",
        "    for x in range(num_catzz):\n",
        "      x = xyy['title'][x]\n",
        "      cat_holder.append(x)\n",
        "      tech = (cat_names['ticker'][cat_names['category']==x])\n",
        "      gg.append(tech)\n",
        "    tech = pd.concat(gg,ignore_index = True)\n",
        "    tech = tech.reset_index()\n",
        "    tech = tech.drop(columns = 'index')\n",
        "    tech = tech.drop_duplicates()\n",
        "    tech = tech['ticker']\n",
        "    aa = pd.DataFrame()\n",
        "    vol = pd.DataFrame()\n",
        "    ss = []\n",
        "    for i in range(len(tech)):\n",
        "      try:\n",
        "        aa[str(tech.iloc[i])] = (df[str(tech.iloc[i])+' Close'].shift(-1*shift) - df[str(tech.iloc[i])+' Open'].shift(shift)).dropna()/df[str(tech.iloc[i])+' Open'].shift(shift).dropna()*100\n",
        "        vol[str(tech.iloc[i])] = df[str(tech.iloc[i])+' Volume']\n",
        "      except:\n",
        "        ss.append(str(tech.iloc[i]))\n",
        "    aa = round(aa)\n",
        "    tech = pd.DataFrame(tech)\n",
        "    dd = pd.DataFrame()\n",
        "    rr = pd.DataFrame()\n",
        "    for x in range(len(tech)):\n",
        "      try:\n",
        "        rr[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "    qq = pd.DataFrame()\n",
        "    for x in range(len(tech)):\n",
        "      try:\n",
        "        qq[tech.iloc[x]] = aa[tech.iloc[x]]\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "    ss = []\n",
        "    df = pd.DataFrame()\n",
        "    for x in range(len(tech)):\n",
        "      try:\n",
        "        df = qq.drop(columns = tech.iloc[x])\n",
        "        ss.append(df)\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "    pieces = []\n",
        "    piecess = []\n",
        "    for x in range(len(tech)):\n",
        "      try:\n",
        "        pieces.append(ss[x].iloc[-1*days_back:-1]) #for the training set\n",
        "        piecess.append(ss[x].iloc[-1*days_back:]) #the test set (using the last x iteration to predict the next return)\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "    df_final = pd.concat(pieces,axis = False, ignore_index = True)\n",
        "    df_finall = pd.concat(piecess,axis= False, ignore_index = True )\n",
        "  else:\n",
        "        print('no setup')\n",
        "  if shift_change == 'on':\n",
        "    y = []\n",
        "    for x in range(len(tech)):\n",
        "      try:\n",
        "        y.append(qq[tech['ticker'][x]].iloc[-1*days_back:].shift(shift*-1).dropna()) #shifting y back 1 to represent xx day(s) returns from xx day(s) returns 1 unit back\n",
        "      except:\n",
        "        print(tech.iloc[x])\n",
        "    y = pd.concat(y, ignore_index = True)\n",
        "    yy =y.reset_index()\n",
        "    yy = yy.drop(columns = 'index')\n",
        "    yy[0].loc[~(yy[0]==0)]\n",
        "    yyy = pd.DataFrame()\n",
        "    yy = yy.dropna()\n",
        "    yyy['y'] = yy[0]\n",
        "    yyy = yyy.reset_index()\n",
        "    tt = round(df_final)\n",
        "    ttt = round(df_finall)\n",
        "    tt = tt.fillna(1)\n",
        "    ttt = ttt.fillna(1)\n",
        "    xx = tt.reset_index()\n",
        "\n",
        "    xx = xx.drop(columns = 'index')\n",
        "    xx = xx.reset_index()\n",
        "    xxx = pd.merge(yyy,xx, on = 'index')\n",
        "    y = xxx['y']\n",
        "    xxx = xxx.drop(columns = ['index','y'])\n",
        "    def clean_dataset(df):\n",
        "      assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "      df.dropna(inplace=True)\n",
        "      indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "      return df[indices_to_keep].astype(np.float64)\n",
        "    xxx = clean_dataset(xxx).reset_index()\n",
        "    yy = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index')\n",
        "    yy = yy['y'].astype(int)\n",
        "    xxx = pd.merge(y.reset_index(),clean_dataset(xxx).reset_index(), on = 'index').drop(columns = ['y','index','level_0']).astype(int)\n",
        "    x = xxx\n",
        "    xx = xxx\n",
        "    xxx = xxx\n",
        "    y = yy\n",
        "    yy = yy\n",
        "    yyy = yy\n",
        "  else:\n",
        "    print('no setup')\n",
        "  if random_forest == 'yes':\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "    clf=RandomForestClassifier(n_estimators=num_trees)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred=clf.predict(X_test)\n",
        "    print('random forest score = '+str(metrics.accuracy_score(y_test, y_pred)))\n",
        "  else:\n",
        "    print('no random forest')\n",
        "  if logi_regression == 'yes':\n",
        "    xx, yy = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "\n",
        "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "    n_scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "  else:\n",
        "    print('no logistic regression')\n",
        "  if gradient_boosted == 'yes':\n",
        "    X_train, X_test, y_train, y_test = train_test_split(xxx, yyy, test_size=0.2)\n",
        "    lr_list = [0.05]\n",
        "    for learning_rate in lr_list:\n",
        "        gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
        "        gb_clf.fit(X_train, y_train)\n",
        "        print(\"Learning rate: \", learning_rate)\n",
        "        print(\"Gradient Boosted Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
        "        print(\"Gradient Boosted Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_test, y_test)))\n",
        "  else:\n",
        "    print('no gradient boosted forests')\n",
        "  if xgb == 'yes':\n",
        "    xgb_clf = XGBClassifier()\n",
        "    xgb_clf.fit(X_train, y_train)\n",
        "    score = xgb_clf.score(X_test, y_test)\n",
        "    print('XGB Score = '+str(score))\n",
        "    xt = x.head(days_back)\n",
        "    yt = x.iloc[days_back:days_back][ticker.upper()]\n",
        "    yt = yt.reset_index().drop(columns = 'index')\n",
        "    df_compare_xgb = pd.DataFrame()\n",
        "    df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "    df_compare_xgb['actual'] = yt\n",
        "    df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "    dd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "    accuracy = dd/len(df_compare_xgb)*100\n",
        "    print('xgb forest accuracy for last '+str(shift)+' '+ticker+' '+str(accuracy))\n",
        "  else:\n",
        "    print('no xg boosted forest')\n",
        "\n",
        "  #testing + graphing\n",
        "  ttt = ttt\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_rf = pd.DataFrame()\n",
        "  df_compare_rf['prediction'] = list(clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_rf.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  yt\n",
        "  df_compare_rf['actual'] = yt\n",
        "  df_compare_rf['dif'] = abs(df_compare_rf['actual']-df_compare_rf['prediction'])\n",
        "  dd = len(df_compare_rf[df_compare_rf['dif']==0])\n",
        "  accuracy = dd/len(df_compare_rf)*100\n",
        "  print('random forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  dd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df_ = {'open':[]}\n",
        "  for x in range(len(dd)):\n",
        "    df_['open'].append(int(dd[x]))\n",
        "  df_final = pd.DataFrame()\n",
        "  df_final[str(ticker.upper())+' prediction'] = df_['open'] + df_compare_rf['prediction']/100*df_['open']\n",
        "  y1 = df_final[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_xgb = pd.DataFrame()\n",
        "  df_compare_xgb['prediction'] = list(xgb_clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_xgb.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  df_compare_xgb['actual'] = yt\n",
        "  df_compare_xgb['dif'] = abs(df_compare_xgb['actual']-df_compare_xgb['prediction'])\n",
        "  ddd = len(df_compare_xgb[df_compare_xgb['dif']==0])\n",
        "  accuracyy = ddd/len(df_compare_xgb)*100\n",
        "  print('xgb forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracyy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  ddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df__ = {'open':[]}\n",
        "  for x in range(len(ddd)):\n",
        "    df__['open'].append(int(ddd[x]))\n",
        "  df_final_xgb = pd.DataFrame()\n",
        "  df_final_xgb[str(ticker.upper())+' prediction'] = df__['open'] + df_compare_xgb['prediction']/100*df__['open']\n",
        "  x11 = df_final_xgb[str(ticker.upper())+' prediction']\n",
        "\n",
        "\n",
        "  xt = ttt.head(days_back+1)\n",
        "  yt = yt.reset_index().drop(columns = 'index')\n",
        "  df_compare_gb = pd.DataFrame()\n",
        "  df_compare_gb['prediction'] = list(gb_clf.predict(xt))\n",
        "  yt = xxx.iloc[days_back:days_back*2][ticker.upper()].append(df_compare_gb.mean()[-1:])\n",
        "  yt = yt.reset_index().drop(columns = 'index')[0]\n",
        "  df_compare_gb['actual'] = yt\n",
        "  df_compare_gb['dif'] = abs(df_compare_gb['actual']-df_compare_gb['prediction'])\n",
        "  dddd = len(df_compare_gb[df_compare_gb['dif']==0])\n",
        "  accuracyyy = dddd/len(df_compare_gb)*100\n",
        "  print('gb forest accuracy for predictions of '+str(shift)+'-day returns of '+ticker+' stock: '+str(accuracyyy))\n",
        "  msft = yf.Ticker(ticker.upper())\n",
        "  df = msft.history(period=\"max\")\n",
        "  dddd = df['Open'].iloc[int(len(df))-days_back-1:]\n",
        "  df___ = {'open':[]}\n",
        "  for x in range(len(dddd)):\n",
        "    df___['open'].append(int(dddd[x]))\n",
        "  df_finalll = pd.DataFrame()\n",
        "  df_finalll[str(ticker.upper())+' prediction'] = df___['open'] + df_compare_gb['prediction']/100*df___['open']\n",
        "  x111 = df_finalll[str(ticker.upper())+' prediction']\n",
        "\n",
        "  df_check = pd.DataFrame()\n",
        "  df_check['rf'] = y1\n",
        "  df_check['gb'] = x111\n",
        "  df_check['xgb'] = x11\n",
        "  df_check['actual'] = dd.reset_index().drop(columns = ['Date']).head(days_back)\n",
        "\n",
        "  plt.figure(figsize = (20, 10))\n",
        "  ax = y1.head(days_back).plot(label='rf prediction')\n",
        "  ax = (df_['open'] + df_compare_rf['actual']/100*df_['open']).plot(label='Actual')\n",
        "  ax = x11.head(days_back).plot(label='xgb prediction')\n",
        "  ax = x111.head(days_back).plot(label='gb prediction')\n",
        "  ax.set_xlabel('Date')\n",
        "  ax.set_ylabel(str(ticker.upper()))\n",
        "  plt.axvline(x = days_back-1, color = 'b', label = 'axvline - full height')\n",
        "\n",
        "  leg = plt.legend()\n",
        "  for line in leg.get_lines():\n",
        "      line.set_linewidth(10)\n",
        "  for text in leg.get_texts():\n",
        "      text.set_fontsize('x-large')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.savefig('predictions plot for '+str(ticker.upper())+'.png')\n",
        "\n",
        "  print(df_check)\n",
        "\n",
        "  def options_chain(symbol):\n",
        "      msft = yf.Ticker(symbol)\n",
        "      exps = msft.options\n",
        "      ops = pd.DataFrame()\n",
        "      for e in exps:\n",
        "          opt = msft.option_chain(e)\n",
        "          opt = pd.DataFrame().append(opt.calls).append(opt.puts)\n",
        "          opt['expirationDate'] = e\n",
        "          ops = ops.append(opt, ignore_index=True)\n",
        "      ops['expirationDate'] = pd.to_datetime(ops['expirationDate']) + timedelta(days = 1)\n",
        "      ops['dte'] = (ops['expirationDate'] - datetime.today()).dt.days\n",
        "      ops['CALL'] = ops['contractSymbol'].str[0:].apply(\n",
        "          lambda x: \"C\" in x)\n",
        "      ops[['bid', 'ask', 'strike']] = ops[['bid', 'ask', 'strike']].apply(pd.to_numeric)\n",
        "      ops['mark'] = (ops['bid'] + ops['ask']) / 2*1000\n",
        "      return ops\n",
        "\n",
        "  df = options_chain(str(ticker.upper())).sort_values('dte',ascending=True)\n",
        "\n",
        "  calls = df[df['CALL']==True]\n",
        "  puts = df[df['CALL']==False]\n",
        "  puts = puts.sort_values('expirationDate',ascending = True)\n",
        "  calls = calls.sort_values('expirationDate',ascending = True)\n",
        "\n",
        "  #black scholes formula\n",
        "  def d1(S,K,T,r,div,sigma):\n",
        "      return(log(S/K)+(r-div+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "  def d2(S,K,T,r,div,sigma):\n",
        "      return d1(S,K,T,r,div,sigma)-sigma*sqrt(T)\n",
        "  def bs_call(S,K,T,r,div,sigma):\n",
        "      return S*norm.cdf(d1(S,K,T,r,div,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,div,sigma))\n",
        "  def bs_put(S,K,T,r,div,sigma):\n",
        "      return K*exp(-r*T)-S+bs_call(S,K,T,r,div,sigma)\n",
        "  print('puts:')\n",
        "  S = current_price\n",
        "  S1 =  float((df_['open'] + df_compare_rf['actual']/100*df_['open']).drop(columns = 'index')[days_back])\n",
        "  difference = S1 - S\n",
        "  pdifference = difference/S\n",
        "\n",
        "  try:\n",
        "    Tp = float(puts['dte'].reset_index().drop(columns = 'index')['dte'][xxe])/365\n",
        "    Kp = float(puts['strike'].reset_index().drop(columns = 'index')['strike'][xxe])\n",
        "    sigmap = float(puts['impliedVolatility'].reset_index().drop(columns = 'index')['impliedVolatility'][xxe])\n",
        "    \n",
        "    #FORMULA: C = price*N( [ln(price/strike)+interest_rate-divYield+vol^2/2)*T]/(vol*sqrt(T)) ] - strike*e^(interest rate * time)*N(d1 - vol*sqrt(T))\n",
        "    print('Black Scholes Results...')\n",
        "    zvvv = str(float((puts['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+puts['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('Price of put: '+zvvv)\n",
        "    zvv = str(Kp-current_price-float((puts['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+puts['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('\"immdiate excercise value\" of put:'+zvv)\n",
        "    zv = str(bs_put(S,Kp,Tp,r,div,sigmap))\n",
        "    print('Black-Scholes expected value of put(from stock open today): '+zv)\n",
        "    zzv = str(Tp)[:4]+' day(s): '+str(bs_put(S1,Kp,Tp,r,div,sigmap))\n",
        "    print('Value of put according to avg of ensemble predictsions in '+zzv)\n",
        "    print(' ---------- ')\n",
        "  except:\n",
        "    print('no puts for '+str(ticker.upper()))\n",
        "  print(' ---------- ')\n",
        "  print('calls:')\n",
        "  try:\n",
        "    Tc = float(calls['dte'].reset_index().drop(columns = 'index')['dte'][xxe])/365\n",
        "    Kc = float(calls['strike'].reset_index().drop(columns = 'index')['strike'][xxe])\n",
        "    sigmac = float(calls['impliedVolatility'].reset_index().drop(columns = 'index')['impliedVolatility'][xxe])\n",
        "    cvvv = str(float((calls['bid'].reset_index().drop(columns = 'index')['bid'][x])+calls['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('Price of call: '+cvvv)\n",
        "    cvv = str(current_price-Kc-float((calls['bid'].reset_index().drop(columns = 'index')['bid'][xxe])+calls['ask'].reset_index().drop(columns = 'index')['ask'][xxe])/2)\n",
        "    print('\"immdiate excercise value\" of call:'+cvv)\n",
        "    cv = str(bs_call(S,Kc,Tc,r,div,sigmac))\n",
        "    print('Black-Scholes expected value of call(from stock open today): '+cv)\n",
        "    ccv = str(Tc)[:]+' day(s): '+str(bs_call(S1,Kc,Tc,r,div,sigmac))\n",
        "    print('Value of call according to avg of ensemble predictsions in '+ccv)\n",
        "  except:\n",
        "    print('no calls for '+str(ticker.upper()))\n",
        "  \n",
        "  return ticker, cvvv, cvv, cv,ccv, zvvv, zvv, zv,zzv, S1, difference, pdifference\n",
        "       # ticker, price of call, immediate excercise value call, BS value, BS pred value, same for put, PRED_PRICE, PRED DIF, PRED P%\n",
        "xcer =0"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "DecisionTreeEnsemble_withOptions.logit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}